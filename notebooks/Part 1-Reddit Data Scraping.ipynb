{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scrapping from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is reddit API PRAW, Enter your DETAILS\n",
    "reddit = praw.Reddit(client_id='APP_CLIENT_ID',\n",
    "                     client_secret='APP_CLIENT_SECRET',\n",
    "                     user_agent='CLIENT_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the available flairs for subreddit askscience\n",
    "# You can change it to any subreddit by replacing the flairs of that subreddit here\n",
    "flairs = ['Physics','Astronomy','Mathematics','Computing','Engineering',\n",
    "          'Chemistry','Earth Sciences','Planetary Sci.','Biology',\n",
    "          'Paleontology','Medicine','Human Body','Neuroscience','Psychology']\n",
    "\n",
    "# Selecting askscience for subreddit\n",
    "# You can choose any subreddit\n",
    "subreddit = reddit.subreddit('SUBREDDIT_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need these features of each posts\n",
    "topics = { \"title\":[], \"url\":[], \"comms_num\": [], \"flair\": [],\n",
    "           \"score\": [], \"id\": [], \"created\": [], \"author\": [], \"body\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fetching data for each flairs and appending it to the dict topics\n",
    "# Setting limit to 20000\n",
    "# We are only fetching root comments as it would take lot of time due to SLOW API\n",
    "# Reddit API is very slow therefore limiting the comments\n",
    "for flair in flairs:\n",
    "    for submission in subreddit.hot(limit=None):\n",
    "        topics[\"flair\"].append(submission.link_flair_text)\n",
    "        topics[\"title\"].append(submission.title)\n",
    "        topics[\"url\"].append(submission.url)\n",
    "        topics[\"comms_num\"].append(submission.num_comments)\n",
    "        topics[\"score\"].append(submission.score)\n",
    "        topics[\"created\"].append(submission.created)\n",
    "        topics[\"author\"].append(submission.author)\n",
    "        topics[\"id\"].append(submission.id)\n",
    "        topics[\"body\"].append(submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics:  1638\n",
      "Astronomy:  714\n",
      "Mathematics:  42\n",
      "Computing:  28\n",
      "Engineering:  308\n",
      "Chemistry:  910\n",
      "Earth Sciences:  1456\n",
      "Planetary Sci.:  448\n",
      "Biology:  3738\n",
      "Paleontology:  252\n",
      "Medicine:  1260\n",
      "Human Body:  1512\n",
      "Neuroscience:  588\n",
      "Psychology:  336\n"
     ]
    }
   ],
   "source": [
    "# Printing no of counts of each flair\n",
    "\n",
    "print(\"Physics: \",str(topics[\"flair\"].count(\"Physics\")))\n",
    "print(\"Astronomy: \",str(topics[\"flair\"].count(\"Astronomy\")))\n",
    "print(\"Mathematics: \",str(topics[\"flair\"].count(\"Mathematics\")))\n",
    "print(\"Computing: \",str(topics[\"flair\"].count(\"Computing\")))\n",
    "print(\"Engineering: \",str(topics[\"flair\"].count(\"Engineering\")))\n",
    "print(\"Chemistry: \",str(topics[\"flair\"].count(\"Chemistry\")))\n",
    "print(\"Earth Sciences: \",str(topics[\"flair\"].count(\"Earth Sciences\")))\n",
    "print(\"Planetary Sci.: \",str(topics[\"flair\"].count(\"Planetary Sci.\")))\n",
    "print(\"Biology: \",str(topics[\"flair\"].count(\"Biology\")))\n",
    "print(\"Paleontology: \",str(topics[\"flair\"].count(\"Paleontology\")))\n",
    "print(\"Medicine: \",str(topics[\"flair\"].count(\"Medicine\")))\n",
    "print(\"Human Body: \",str(topics[\"flair\"].count(\"Human Body\")))\n",
    "print(\"Neuroscience: \",str(topics[\"flair\"].count(\"Neuroscience\")))\n",
    "print(\"Psychology: \",str(topics[\"flair\"].count(\"Psychology\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to dataframe\n",
    "topics_df = pd.DataFrame(topics)\n",
    "# Convert dataframe to csv file\n",
    "topics_df.to_csv('../data/askscience1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
