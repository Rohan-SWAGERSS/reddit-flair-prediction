{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import gensim\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import our data\n",
    "data = pd.read_csv('../data/processedasksciencefinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = ['Physics','Astronomy','Mathematics','Computing','Engineering',\n",
    "          'Chemistry','Earth Sciences','Planetary Sci.','Biology',\n",
    "          'Paleontology','Medicine','Human Body','Neuroscience','na','Psychology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our data into train and test\n",
    "# We will use 75:25 rule, 75% for train and 25% for test\n",
    "# Let's create the function for it\n",
    "# we will use train_test_split function for it which comes with sklearn\n",
    "# setting random state to 10, we can set it to any fixed value\n",
    "\n",
    "def train_test(X,y): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 10)\n",
    "    print(\"Naive Bayes Classifier \")\n",
    "    naivebayes_classifier(X_train, X_test, y_train, y_test)\n",
    "    print(\"Linear Support Vector Machine \")\n",
    "    lsvm(X_train, X_test, y_train, y_test)\n",
    "    print(\"Logistic Regression \")\n",
    "    logistic_regression(X_train, X_test, y_train, y_test)\n",
    "    print(\"Random Forest \")\n",
    "    random_forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function for each classifier\n",
    "\n",
    "# Naive Bayes\n",
    "def naivebayes_classifier(X_train, X_test, y_train, y_test):\n",
    "    nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ])\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    print(\"Accuracy: \"+str(accuracy_score(y_pred,y_test)))\n",
    "\n",
    "# Linear Support Vector Machine\n",
    "def lsvm(X_train, X_test, y_train, y_test):\n",
    "    sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=10, max_iter=5, tol=None)),\n",
    "                 ])\n",
    "    sgd.fit(X_train, y_train)\n",
    "    y_pred = sgd.predict(X_test)\n",
    "    print(\"Accuracy: \"+str(accuracy_score(y_pred,y_test)))\n",
    "\n",
    "# Logistic Regression\n",
    "def logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=1, C=1e30)),\n",
    "                 ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print(\"Accuracy: \"+str(accuracy_score(y_pred,y_test)))\n",
    "    \n",
    "# Random Forest\n",
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    ranfor = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 10)),\n",
    "                 ])\n",
    "    ranfor.fit(X_train, y_train)\n",
    "    y_pred = ranfor.predict(X_test)\n",
    "    print(\"Accuracy: \"+str(accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Title as a Feature:\n",
      "---------------------------------------\n",
      "Naive Bayes Classifier \n",
      "Accuracy: 0.9795918367346939\n",
      "Linear Support Vector Machine \n",
      "Accuracy: 0.9925265881000287\n",
      "Logistic Regression \n",
      "Accuracy: 0.999137683242311\n",
      "Random Forest \n",
      "Accuracy: 0.999137683242311\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "print(\"Flair Detection using Title as a Feature:\")\n",
    "print(\"---------------------------------------\")\n",
    "train_test(data.title, data.flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Body as a Feature:\n",
      "---------------------------------------\n",
      "Naive Bayes Classifier \n",
      "Accuracy: 0.7936188559931014\n",
      "Linear Support Vector Machine \n",
      "Accuracy: 0.7755102040816326\n",
      "Logistic Regression \n",
      "Accuracy: 0.8177637252083932\n",
      "Random Forest \n",
      "Accuracy: 0.8177637252083932\n"
     ]
    }
   ],
   "source": [
    "print(\"Flair Detection using Body as a Feature:\")\n",
    "print(\"---------------------------------------\")\n",
    "train_test(data.body, data.flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Detection using Title+Body+URL as a Feature:\n",
      "---------------------------------------\n",
      "Naive Bayes Classifier \n",
      "Accuracy: 0.9833285426846795\n",
      "Linear Support Vector Machine \n",
      "Accuracy: 0.9971256108077033\n",
      "Logistic Regression \n",
      "Accuracy: 1.0\n",
      "Random Forest \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Flair Detection using Title+Body+URL as a Feature:\")\n",
    "print(\"---------------------------------------\")\n",
    "train_test(data.feature_tbu, data.flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After detailed analysis of all the metrics!\n",
    "### Combined feature of Title, Body and URL performed better than others.\n",
    "### Logistic Regression performed better than other algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91971\\Desktop\\reddit-flair-prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X=data.feature_tbu\n",
    "y=data.flair\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 10)\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=1, C=1e30)),\n",
    "                 ])\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Dump our model\n",
    "pickle.dump(logreg, open('../models/final_model_askscience.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
